## 2019-05-22-郭叙森  周报

上次讨论留下了几个问题：

一、对于远处小物体以及超出图像边界的物体的检测性能不好是 AVOD 原模型就存在的问题还是我们改进的 Bi-AVOD 新出现的问题？ 
答： 

对于远处小物体的检测，AVOD 源模型检测性能也不好，对于没有点云信息的物体，基本检测不出。所以该问题应为 AVOD 模型本身存在的。

而对于超出图像边界的物体，AVOD 源模型也会存在检测不出的情况，且没有规律，只是大多数情况还是能够正常检测出的，而我们的 Bi-AVOD 基本检测不出，所以针对该场景我们改进的模型还是与原模型存在较大差距的。

针对该问题，我认为是我们的模型无法处理轨迹在两关键帧之间终止的情况，这样在关键帧之间的有车辆超出了视野，下一个关键帧就没有该物体，从而该轨迹在上一关键帧就终止了，漏检了关键帧之间的物体框。

二、找找有没有结构光数据集

目前还未发现有相关数据集。

三、AVOD 模型多传感器融合的有效性实验
我们 针对 AVOD 分别做了三个实验，雷达数据+图像数据， 只用雷达数据， 以及只用图像数据，最终的结果如下：

点云 + 图像

![1558537821976](/home/mooyu/.config/Typora/typora-user-images/1558537821976.png)

只有图像

![1558537968695](/home/mooyu/.config/Typora/typora-user-images/1558537968695.png)

只有点云

![1558538023081](/home/mooyu/.config/Typora/typora-user-images/1558538023081.png)



从以上结果对比可以看出，融合过程中图像的信息没有很好的利用，只用点云取得的结果接近同时用点云与图像。

这一块对照实验还得接着做，不过可以肯定这里有很大的提升空间，特别是对于点云上没有信息的而在图像上比较小的物体，这可以使接下来工作的一个重点。



对于轨迹卷积相关的探究，目前进展缓慢，最近在改进原来Bi-AVOD 的代码，也在看一些视频处理的一些文章，希望从中找到启发。

